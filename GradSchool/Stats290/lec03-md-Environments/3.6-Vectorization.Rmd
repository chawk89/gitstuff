---
title: "3.6. Vectorization"
output:
     slidy_presentation
---
```{r, echo = FALSE}
## Install the microbenchmark package if needed
installIfNeeded <- function(packages, ...) {
  for (package in packages) {
    installedPackages <- installed.packages()[, 1]
    if (! (package %in% installedPackages))
      install.packages(package, repos = "https://cloud.r-project.org")
  }
}
installIfNeeded(c("microbenchmark", "cubature"))
library(microbenchmark)
```

Since everything is R is done via functions, we need to understand the
cost of using functions. As we saw, the scoping rules mean that R is a
dynamically scoped language: the variables are looked up according to
rules and if the environments where the function is evaluated changes,
so will the results.

This has implications for designing functions. As you can expect, the
cost of those look ups is significant. So we should examine ways to
make our code run more efficiently.

One important technique is vectorization. Essentially, instead of
evaluating and returning the value of a function for one value of the
argument, it pays to design functions that work on whole vectors at a
time. The cost savings can be enormous, particularly for numerical
work.

___

_Many functions in R are designed to work on vectors!_  So exploit
them.

## 3.6.1.  Examples

```{r}
x <- 1:10
x %% 2
x > 0
ifelse(x > 5, 0, 1)
```

As a comparison, let compare the speed of vectorized versus
non-vectorized code.  To do this, we use the `microbenchmark`
package.

We will compute the minimum of two vectors, element by element.

```{r}
N <- 1000
x <- rnorm(N); y <- rnorm(N)
nvMin <- function() {
    z <- numeric(N)
    for (i in seq(N)) z[i] <- if (x[i] < y[i]) x[i] else y[i]
    z
}
vMin <- function() ifelse(x < y, x, y)
```

Let us benchmark this.

```{r}
d <- summary(microbenchmark(nvMin(), vMin()))
kable(d)
```

The vectorized versions yield a significant performance gain. 


## 3.6.2. A larger example

This is a larger example from my
[`cubature`](https://cran.r-project.org/package=cubature) package on
CRAN.

```{r}
library(cubature)

harness <- function(which = NULL,
                    f, fv, lowerLimit, upperLimit, tol = 1e-3, times = 20, ...) {

    fns <- c(hc = "Non-vectorized Hcubature",
             hc.v = "Vectorized Hcubature")

    hc <- function() cubature::hcubature(f = f,
                                         lowerLimit = lowerLimit,
                                         upperLimit = upperLimit,
                                         tol = tol,
                                         ...)

    hc.v <- function() cubature::hcubature(f = fv,
                                           lowerLimit = lowerLimit,
                                           upperLimit = upperLimit,
                                           tol = tol,
                                           vectorInterface = TRUE,
                                           ...)

    ndim = length(lowerLimit)

    if (is.null(which)) {
        fnIndices <- seq_along(fns)
    } else {
        fnIndices <- match(which, names(fns))
    }
    fnList <- lapply(names(fns)[fnIndices], function(x) call(x))
    argList <- c(fnList, unit = "ms", times = times)
    result <- do.call(microbenchmark, args = argList)
    d <- summary(result)
    d$expr <- fns[fnIndices]
    d
}
```

Using `cubature`, we evaluate
$$
\int_R\phi(x)dx
$$
where $\phi(x)$ is the three-dimensional multivariate normal density with mean
0, and variance
$$
\Sigma = \left(\begin{array}{rrr}
1 &\frac{3}{5} &\frac{1}{3}\\
\frac{3}{5} &1 &\frac{11}{15}\\
\frac{1}{3} &\frac{11}{15} & 1
\end{array}
\right)
$$
and $R$ is $[-\frac{1}{2}, 1] \times [-\frac{1}{2}, 4] \times [-\frac{1}{2}, 2].$

We construct a scalar function (`my_dmvnorm`) and a vector analog
(`my_dmvnorm_v`). First the functions.

```{r}
m <- 3
sigma <- diag(3)
sigma[2,1] <- sigma[1, 2] <- 3/5 ; sigma[3,1] <- sigma[1, 3] <- 1/3
sigma[3,2] <- sigma[2, 3] <- 11/15

## Non-vectorized function
my_dmvnorm <- function (x, mean, sigma) {
    x <- matrix(x, ncol = length(x))
    distval <- stats::mahalanobis(x, center = mean, cov = sigma)
    logdet <- sum(log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values))
    exp(-(ncol(x) * log(2 * pi) + logdet + distval)/2)
}

## vectorized function
my_dmvnorm_v <- function (x, mean, sigma) {
    distval <- stats::mahalanobis(t(x), center = mean, cov = sigma)
    logdet <- sum(log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values))
    exp(matrix(-(nrow(x) * log(2 * pi) + logdet + distval)/2, ncol = ncol(x)))
}
```

Now the timing.

```{r}
d <- harness(f = my_dmvnorm, fv = my_dmvnorm_v,
             lowerLimit = rep(-0.5, 3),
             upperLimit = c(1, 4, 2),
             tol = 1e-5,
             times = 10,
             mean = rep(0, m), sigma = sigma)
knitr::kable(d, digits = 3)
```

## 3.6.3. Summary

A computation in R is vectorized if the number of R function calls is
independent of $N$, where N is the natural measure of the size of the
computation (length of vector, no. of rows of table,
etc.)

The heuristic guideline is: Try to replace loops of length
proportional to $N$ with a smaller number of function calls
producing the same result, usually calls not requiring a loop in R
of order $N$ in length.

Vectorization can yield massive performance gains, especially in many
computations involving array like structures. It can also be fun but
beware of premature optimization.

___

Techniques are

- Look to use functions that operate on whole objects.

- Filtering & transforming whole vector: arithmetic,
`ifelse()`, logical indexing `x[expression]` etc.

- Form a matrix from 1 or 2 vectors, with `outer()`, do
  some computations on it, reduce back with matrix arithmetic,
    `rowMeans()`, etc.

- Form a list of (a few) subsets with `split()`, compute
    on that, recombine with `unsplit()`, for example.

- Restructure a matrix (change the dim attribute) to match row,
  column indices with some offsets

- Remember to check that the functions you use are vectorized
    (Primitives, `.Internal`, or calls to C/Fortran, or no loops and
    then check the functions they call.

Just that there is no confusion, the `apply` series of functions is
_not_ vectorized: they call the function multiple times for each
argument. This is, however, not an argument against their use. In
fact, they are good idioms to exploit appropriately to make programs
more succint and readable.


## Session Info
```{r}
sessionInfo()
```
